{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AkuPusingMas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcOJNmCB1CK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "31d0543e-2e1b-4223-b2c8-488493574e27"
      },
      "source": [
        "from google.colab import drive; drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYbue8r-ptUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e1324306-3307-452a-95e8-e1726098475a"
      },
      "source": [
        "#pip install --upgrade tensorflow-gpu\n",
        "#!pip install Keras==2.2.4\n",
        "!pip install tokenizers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.8.1rc2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nekFGFpBY4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "afacfed4-949a-40d3-a720-569e71ce3dc5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import sentencepiece as spm\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from tokenizers import ByteLevelBPETokenizer\n",
        "from keras import backend as K\n",
        "print(\"Tf\",tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tf 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VWe8Nd_8ee2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "dad2a6b9-bc8e-4d94-aa08-be8d3c649875"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaFTp1T5UG4u",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJE6XonlC0cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HXeENPACdrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  from transformers import XLMRobertaTokenizer\n",
        "  from transformers import XLMRobertaModel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6U3PIasB0ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 128  \n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "PATH = \"/content/drive/My Drive/Gemastik/XLMRoberta\"\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"jplu/tf-xlm-roberta-large\",lowercase = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0vwUt3Bve_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "traindf = pd.read_excel(\"/content/drive/My Drive/hasil_preprocessing_kamusKita_kamusInternet (1).xlsx\")\n",
        "traindf.drop([\"Unnamed: 0\"],axis = 1,inplace = True)\n",
        " #traindf = pd.read_csv(\"/content/drive/My Drive/Gemastik/DatasetLabeled.csv\",delimiter = \"\\t\")\n",
        " #traindf.head()\n",
        " #traindf5000 = traindf[:5000]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVqo5Y-L6iAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "1e301e61-eda5-4444-9428-090b47d7bd80"
      },
      "source": [
        "traindf = traindf[[\"hasil_akhir_preprocessing\",\"sentiment\"]]\n",
        "traindf.dropna(inplace = True)\n",
        "traindf[\"sentiment\"] = traindf[\"sentiment\"].astype('float32')\n",
        "print(len(traindf))\n",
        "traindf.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hasil_akhir_preprocessing</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stayathome withmestudy bahas uji sekolah onlen</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nasehat untuk pemuda ini rupa daily voice lett...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dari kampusny memang sudah ada elearning broth...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hmm kemarin teman kelas telepon iya inti kenap...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>serius stres banget ngadepin ajar jarak jauh ini</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           hasil_akhir_preprocessing  sentiment\n",
              "2     stayathome withmestudy bahas uji sekolah onlen        1.0\n",
              "3  nasehat untuk pemuda ini rupa daily voice lett...        1.0\n",
              "4  dari kampusny memang sudah ada elearning broth...        1.0\n",
              "5  hmm kemarin teman kelas telepon iya inti kenap...        0.0\n",
              "7   serius stres banget ngadepin ajar jarak jauh ini        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsgOv-fuoaQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regular_encode(texts, tokenizer = tokenizer, maxlen=128):\n",
        "    enc_di = tokenizer.batch_encode_plus(\n",
        "        texts, \n",
        "        max_length=maxlen,\n",
        "        return_attention_mask = False,\n",
        "        return_token_type_ids = False,\n",
        "        pad_to_max_length = True,\n",
        "        truncation = True\n",
        "        \n",
        "    )\n",
        "    \n",
        "    return np.array(enc_di[\"input_ids\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbgFKttZvxo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56LONE-D1ZVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "fd555bb2-7791-4726-f917-462c030c20dd"
      },
      "source": [
        "traindfonlyBalancePos = traindf[traindf[\"sentiment\"] == 1]\n",
        "traindfonlyBalanceNeg = traindf[traindf[\"sentiment\"] == 0] \n",
        "traindfonlyBalanceNeg = traindfonlyBalanceNeg[:1040]\n",
        "BalanceDf = pd.concat([traindfonlyBalancePos,traindfonlyBalanceNeg])\n",
        "\n",
        "BalanceDf = BalanceDf.sample(frac=1).reset_index(drop=True)\n",
        "(len(traindfonlyBalanceNeg) , len(traindfonlyBalancePos))\n",
        "BalanceDf.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hasil_akhir_preprocessing</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>guru gerak kim web kukar gelar ajar daring lal...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ket mau tweet e takon sekolah sahaja yang tanya</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>selamat siang universitas buka adalah guru tin...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ini adik aku yang marah gara-gara sekolah engg...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yakali nanti kenangannyaa social</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           hasil_akhir_preprocessing  sentiment\n",
              "0  guru gerak kim web kukar gelar ajar daring lal...        1.0\n",
              "1    ket mau tweet e takon sekolah sahaja yang tanya        1.0\n",
              "2  selamat siang universitas buka adalah guru tin...        1.0\n",
              "3  ini adik aku yang marah gara-gara sekolah engg...        0.0\n",
              "4                   yakali nanti kenangannyaa social        1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZk06fkjXFUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "79aa1773-e40a-44bf-9f15-9862ab82cca8"
      },
      "source": [
        "BalanceDf[\"Encoded\"] = BalanceDf[\"hasil_akhir_preprocessing\"].apply(regular_encode)\n",
        "BalanceDf.loc[0,\"Encoded\"]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,  706,    2, ...,    1,    1,    1],\n",
              "       [   0,   75,    2, ...,    1,    1,    1],\n",
              "       [   0, 1690,    2, ...,    1,    1,    1],\n",
              "       ...,\n",
              "       [   0,   81,    2, ...,    1,    1,    1],\n",
              "       [   0,   17,    2, ...,    1,    1,    1],\n",
              "       [   0,   10,    2, ...,    1,    1,    1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KRDxojEviDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f5745473-742b-4e4e-9c31-5bea6f41f37d"
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(BalanceDf[\"hasil_akhir_preprocessing\"],BalanceDf[\"sentiment\"],\n",
        "                                               test_size = 0.25, random_state = 0)\n",
        "x_Encoded = regular_encode(x_train,tokenizer,MAX_LEN)\n",
        "x_valEncoded = regular_encode(x_val,tokenizer,MAX_LEN)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_JxgjG0nULZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train,num_classes = 2)\n",
        "y_val = to_categorical(y_val,num_classes = 2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxcoBQDLng0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L9-4yPq14Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_Encoded, y_train))\n",
        "    .batch(32)\n",
        "    .repeat()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkaEADAY14sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_valEncoded, y_val))\n",
        "    .batch(32)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-k1pUnQIW6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import TFAutoModel"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J4wnIbXlJWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "057b80ed-ee75-4bce-99c7-bb01b436d026"
      },
      "source": [
        "import keras\n",
        "def main_model():\n",
        "  config = XLMRobertaConfig.from_pretrained(\"jplu/tf-xlm-roberta-large\")\n",
        "  config.num_labels = 2\n",
        "  METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]  \n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "  with strategy.scope():\n",
        "    ENCODER = TFAutoModel.from_pretrained(\"jplu/tf-xlm-roberta-base\")\n",
        "    input_ids = tf.keras.layers.Input(shape=(MAX_LEN), dtype=tf.int32)\n",
        "    input_masks = tf.keras.layers.Input(shape = (MAX_LEN), dtype= tf.int32 , name = \"input_maks\")\n",
        "    input_Token = tf.keras.layers.Input(shape = (MAX_LEN), dtype= tf.int32 , name = \"input_Token_type\")\n",
        "\n",
        "    inputs = [input_ids, input_masks, input_Token] \n",
        "\n",
        "      # Add a hidden layer\n",
        "      #x = tf.keras.layers.Dense(units=768, activation='relu')(pooled_output)\n",
        "      #x = tf.keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "      # Add output layer\n",
        "      #outputs = Dense(1, activation=\"sigmoid\")(x)# Construct a new model\n",
        "\n",
        "\n",
        "    embedding, sequence_output = ENCODER(input_ids)\n",
        "      #Disini Boleh Di adjust  \n",
        "    logits = embedding[:,0,:]\n",
        "    logits = tf.keras.layers.Dropout(0.2)(logits)\n",
        "    logits = tf.keras.layers.Dense(64,\"relu\")(logits)\n",
        "    logits = tf.keras.layers.Dropout(0.4)(logits)\n",
        "    outputs = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"final_output\")(logits)\n",
        "    model = tf.keras.Model(inputs=input_ids, outputs=outputs)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=1e-5)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "      #for layer in model.layers[:2]:\n",
        "      #  layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=METRICS)\n",
        "  return model\n",
        "\n",
        "model = main_model()\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "tfxlm_roberta_model_2 (TFXLM ((None, 128, 768), (None, 278043648 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice_2  [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_118 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                49216     \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "final_output (Dense)         (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 278,092,994\n",
            "Trainable params: 278,092,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzAgHu-7KSN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_learning_rate_scheduler(max_learn_rate=1e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwHFOFkQsJJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "41cd5eaa-d50c-42da-96d8-d044d17d6228"
      },
      "source": [
        "\n",
        "total_epoch_count = 50\n",
        "n_steps = x_train.shape[0]\n",
        "history = model.fit(train_dataset,\n",
        "          validation_data=valid_dataset,\n",
        "          steps_per_epoch =n_steps,\n",
        "          epochs=total_epoch_count)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_2/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_2/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_2/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model_2/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "  70/1560 [>.............................] - ETA: 12:24 - loss: 0.7409 - tp: 1087.0000 - fp: 1145.0000 - tn: 1087.0000 - fn: 1145.0000 - accuracy: 0.4870 - precision: 0.4870 - recall: 0.4870 - auc: 0.4834"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlvugqoxZXib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J2zH4i9RPlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQEz-QtC95K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_save_location = \"/content/drive/My Drive/Gemastik/XLMROBERTA.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvhi0VTcUeh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save_weights(model_save_location, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUS6qlVbAc4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = np.array(traindf[\"sentiment\"]).reshape(-1,1)\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV3Q9zfL_72h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_freqs(labels):\n",
        "  '''\n",
        "  Purpose : \"compute Positive and negative frequencies\"\n",
        "  Args : labels(np.array): size(num_examples,num_class)\n",
        "  \n",
        "  returns positive_frequencies and Negative Frequencies\n",
        "  '''\n",
        "  labels = labels.reshape(-1,1)\n",
        "  N = labels.shape[0]\n",
        "  positive_frequencies = np.sum(labels,axis = 0) /  N\n",
        "  negative_frequencies = 1 - positive_frequencies \n",
        "\n",
        "  return positive_frequencies,negative_frequencies\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtKAcIitCGM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pos,test_neg= compute_freqs(label)\n",
        "print(f\"Pos freqs : {test_pos}\")\n",
        "print(f\"Neg Freqs: {test_neg}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TDQt8pmCsu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq_pos,freq_neg = compute_freqs(y_train.values)\n",
        "print(f\"Pos freqs : {freq_pos}\")\n",
        "print(f\"Neg Freqs : {freq_neg}\")\n",
        "\n",
        "class_weight = {1: freq_neg, 0: freq_pos}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bx9pOjdDk2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg = traindf[\"sentiment\"][traindf[\"sentiment\"] == 0].value_counts().values[0]\n",
        "pos = traindf[\"sentiment\"][traindf[\"sentiment\"] == 1].value_counts().values[0]\n",
        "total = pos + neg\n",
        "weight_for_0 = (1 / neg) *(total)\n",
        "weight_for_1 = (1/ pos) *(total)\n",
        "\n",
        "print(total)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZEr0tp0_z_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "#model.load_weights(filepath=\"/content/drive/My Drive/Gemastik/XLMROBERTA.h5\")\n",
        "Preloadedmodel = model\n",
        "def FineTuningModel(models):\n",
        "  METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "  #dditionalLayer = tf.keras.layers.Dense(2048,activation = 'tanh')\n",
        "  models.layers[-2] = models.layers[-2].trainable = True\n",
        "  models.layers[-4] = models.layers[-4].trainable = True\n",
        "  #models.layers[-4] = additionalLayer\n",
        "  loss = tf.keras.losses.BinaryCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=2e-5)\n",
        "\n",
        "  models.compile(optimizer = optimizer , loss = loss ,metrics = METRICS)\n",
        "\n",
        "  return models\n",
        "\n",
        "FineTunedModel = FineTuningModel(Preloadedmodel)\n",
        "FineTunedModel.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CleA_97z_2fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(traindf[\"hasil_akhir_preprocessing\"],traindf[\"sentiment\"],\n",
        "                                               test_size = 0.25, random_state = 0)\n",
        "x_train = regular_encode(x_train,tokenizer,MAX_LEN)\n",
        "x_val = regular_encode(x_val,tokenizer,MAX_LEN)\n",
        "print(x_train.shape,x_val.shape,y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSUeP9K54T5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ZeyXUQAjVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(2048)\n",
        "    .batch(64)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((x_val, y_val))\n",
        "    .batch(64)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quIcZTSA3ck6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_weighted_pixelwise_crossentropy(target, output):\n",
        "    output = tf.clip_by_value(output, 10e-8, 1.-10e-8)\n",
        "    with open('class_weights.pickle', 'rb') as f:\n",
        "        weight = pickle.load(f)\n",
        "    return -tf.reduce_sum(target * weight * tf.log(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTrrAivsAy7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1024 \n",
        "ITERATION = 3649 / BATCH_SIZE # tOTAL DATASET / bATCHSIZE\n",
        "total_epoch_count = round(BATCH_SIZE) * round(ITERATION)\n",
        "n_steps = x_train.shape[0]\n",
        "FineTunedModel.fit(x = x_train,y = y_train,\n",
        "          shuffle = True,\n",
        "          validation_data=valid_dataset,\n",
        "          epochs=total_epoch_count, \n",
        "          workers = -1,\n",
        "          batch_size = 32,\n",
        "          callbacks=[create_learning_rate_scheduler(max_learn_rate=1e-5,\n",
        "                                                    end_learn_rate=1e-7,\n",
        "                                                    warmup_epoch_count=20,\n",
        "                                                    total_epoch_count=total_epoch_count),\n",
        "                     keras.callbacks.EarlyStopping(patience=5),\n",
        "                     ]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYtQPwo3AA6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install numba\n",
        "#from numba import cuda \n",
        "#device = cuda.get_current_device()\n",
        "#device.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiKjrkuY9xzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.evaluate(x_val,y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiD_o-cZm3e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}